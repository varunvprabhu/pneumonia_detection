{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import h5py\n",
    "import tables\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import functools\n",
    "from functools import reduce\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stage_1_train_labels.csv')\n",
    "df_class = pd.read_csv('../data/stage_1_detailed_class_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_ids = []\n",
    "for j in range(df.shape[0]):\n",
    "    all_img_ids.append(df['patientId'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_ids = shuffle(all_img_ids, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "\n",
    "      parsed = {\n",
    "        \n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "\n",
    "      }\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Define lambda to extract coords in list [y, x, height, width]\n",
    "    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]\n",
    "\n",
    "    parsed = {}\n",
    "    for n, row in df.iterrows():\n",
    "        # --- Initialize patient entry into parsed \n",
    "        pid = row['patientId']\n",
    "        if pid not in parsed:\n",
    "            parsed[pid] = {\n",
    "                'dicom': '../data/stage_1_train_images/%s.dcm' % pid,\n",
    "                'label': row['Target'],\n",
    "                'boxes': []}\n",
    "\n",
    "        # --- Add box if opacity is present\n",
    "        if parsed[pid]['label'] == 1:\n",
    "            parsed[pid]['boxes'].append(extract_box(row))\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(data):\n",
    "    \"\"\"\n",
    "    Method to draw single patient with bounding box(es) if present \n",
    "\n",
    "    \"\"\"\n",
    "    # --- Open DICOM file\n",
    "    d = pydicom.read_file(data['dicom'])\n",
    "    im = d.pixel_array\n",
    "\n",
    "    # --- Convert from single-channel grayscale to 3-channel RGB\n",
    "    im = np.stack([im] * 3, axis=2)\n",
    "\n",
    "    # --- Add boxes with random color if present\n",
    "    for box in data['boxes']:\n",
    "        rgb = [255,0,0]#np.floor(np.random.rand(3) * 256).astype('int')\n",
    "        im = overlay_box(im=im, box=box, rgb=rgb, stroke=6)\n",
    "\n",
    "    pylab.imshow(im,cmap=pylab.cm.gist_gray)\n",
    "\n",
    "def overlay_box(im, box, rgb, stroke=1):\n",
    "    \"\"\"\n",
    "    Method to overlay single box on image\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Convert coordinates to integers\n",
    "    box = [int(b) for b in box]\n",
    "    \n",
    "    # --- Extract coordinates\n",
    "    y1, x1, height, width = box\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "\n",
    "    im[y1:y1 + stroke, x1:x2] = rgb\n",
    "    im[y2:y2 + stroke, x1:x2] = rgb\n",
    "    im[y1:y2, x1:x1 + stroke] = rgb\n",
    "    im[y1:y2, x2:x2 + stroke] = rgb\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this ensures the program can use all the gpu resources it can get\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "def weight_initializer(weight_input, output_channel_size, filter_size): #, layer_num\n",
    "    \n",
    "    _, rows, columns, input_channel_size = [i.value for i in weight_input.get_shape()]\n",
    "    \n",
    "    weight_shape = [filter_size,filter_size,input_channel_size,output_channel_size]\n",
    "\n",
    "    weight_output = tf.Variable(tf.contrib.layers.xavier_initializer(uniform = False)(weight_shape))\n",
    "    \n",
    "    #weight_output = tf.get_variable(shape = weight_shape, dtype=tf.float32, \n",
    "                                    #initializer = tf.contrib.layers.xavier_initializer(uniform = False)) \n",
    "    #name = \"weight-\" + str(layer_num),\n",
    "    \n",
    "    return weight_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution block \n",
    "def conv2d(block_input, num_filters, filter_size = 1, stride_length = 1): #, layer_num\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size) #, layer_num\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    block_output = tf.nn.conv2d(block_input,init_weights,strides,padding='VALID')\n",
    "    \n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(block_input, num_filters, filter_size = 1, stride_length = 1): #, layer_num\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size) #, layer_num\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    \n",
    "    block_output = tf.nn.conv2d(block_input,init_weights,strides,padding='VALID')\n",
    "    normalized = tf.contrib.layers.batch_norm(block_output, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(block_input, num_filters):\n",
    "    norm_1 = tf.contrib.layers.batch_norm(block_input, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    conv_1 = conv2d(norm_1, int(num_filters/2), 1, 1)\n",
    "    norm_2 = tf.contrib.layers.batch_norm(conv_1, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    pad = tf.pad(norm_2, np.array([[0,0],[1,1],[1,1],[0,0]]))\n",
    "    conv_2 = conv2d(pad, int(num_filters/2), 3, 1)\n",
    "    norm_3 = tf.contrib.layers.batch_norm(conv_2, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    conv_3 = conv2d(norm_3, int(num_filters), 1, 1)\n",
    "    \n",
    "    return conv_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_layer(block_input, num_filters):\n",
    "    \n",
    "    if (block_input.get_shape()[3] == num_filters):\n",
    "        return block_input\n",
    "    else:\n",
    "        conv = conv2d(block_input, num_filters,1,1)\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(block_input, num_filters):\n",
    "    conv = conv_block(block_input, num_filters)\n",
    "    skip = skip_layer(block_input, num_filters)\n",
    "    \n",
    "    return(tf.add_n([conv,skip]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourglass_unit(input_data, reduction_factor, num_filters):\n",
    "    up_1 = residual(input_data, num_filters)\n",
    "    low = tf.contrib.layers.max_pool2d(input_data, [2,2],[2,2], 'VALID')\n",
    "    low_1 = residual(low, num_filters)\n",
    "    \n",
    "    if reduction_factor > 0:\n",
    "        low_2 = hourglass_unit(low_1, reduction_factor - 1, num_filters)\n",
    "    else:\n",
    "        low_2 = residual(low_1, num_filters)\n",
    "    \n",
    "    low_3 = residual(low_2, num_filters)\n",
    "    up_sample = tf.image.resize_nearest_neighbor(low_3, tf.shape(low_3)[1:3]*2)\n",
    "    return tf.add_n([up_1, up_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourglass_model(input_data, num_blocks, num_filters, reduction_factor, train_model):\n",
    "    pad_1 = tf.pad(input_data, np.array([[0,0],[2,2],[2,2],[0,0]]))\n",
    "    conv_1 = conv2d(pad_1, 64,6,2)\n",
    "    res_1 = residual(conv_1, 128)\n",
    "    pool_1 = tf.contrib.layers.max_pool2d(res_1, [2,2], [2,2], padding= 'VALID')\n",
    "    res_2 = residual(pool_1, 128)\n",
    "    res_3 = residual(res_2, num_filters)\n",
    "    \n",
    "    x1 = [None] * num_blocks\n",
    "    x2 = [None] * num_blocks\n",
    "    x3 = [None] * num_blocks\n",
    "    x4 = [None] * num_blocks\n",
    "    x5 = [None] * num_blocks\n",
    "    x6 = [None] * num_blocks\n",
    "    sum_all = [None] * num_blocks\n",
    "    \n",
    "    x1[0] = hourglass_unit(res_3, reduction_factor, num_filters)\n",
    "    x2[0] = conv_bn_relu(x1[0], num_filters)\n",
    "    x3[0] = conv2d(x2[0], num_filters, 1, 1)\n",
    "    x4[0] = tf.layers.dropout(x3[0], rate = 0.1, training = train_model)\n",
    "    x5[0] = conv2d(x2[0], num_filters, 1, 1)\n",
    "    x6[0] = conv2d(x5[0], num_filters, 1, 1)\n",
    "    sum_all[0] = tf.add_n([x4[0], x6[0], res_3])\n",
    "    \n",
    "    for i in range(1, num_blocks - 1):\n",
    "        x1[i] = hourglass_unit(sum_all[i-1], reduction_factor, num_filters)\n",
    "        x2[i] = conv_bn_relu(x1[i], num_filters)\n",
    "        x3[i] = conv2d(x2[i], num_filters, 1, 1)\n",
    "        x4[i] = tf.layers.dropout(x3[i], rate = 0.1, training = train_model)\n",
    "        x5[i] = conv2d(x2[i], num_filters, 1, 1)\n",
    "        x6[i] = conv2d(x5[i], num_filters, 1, 1)\n",
    "        sum_all[i] = tf.add_n([x4[i], x6[i], sum_all[i-1]])\n",
    "    \n",
    "    x1[num_blocks - 1] = hourglass_unit(sum_all[num_blocks - 2], reduction_factor, num_filters)\n",
    "    x2[num_blocks - 1] = conv_bn_relu(x1[num_blocks - 1], num_filters)\n",
    "    x4[num_blocks - 1] = tf.layers.dropout(x2[num_blocks - 1], rate = 0.1, training = train_model)\n",
    "    x5[num_blocks - 1] = conv2d(x4[num_blocks - 1], 3, 1, 1)\n",
    "    final_output = tf.image.resize_nearest_neighbor(x5[num_blocks - 1], tf.shape(x5[num_blocks - 1])[1:3]*2)\n",
    "    #final_output = x5[num_blocks - 1]\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "number_train_images = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lung_imgs(index1, index2, aug):\n",
    "    \n",
    "    if aug:\n",
    "        X_batch = np.zeros((batch_size*4,256,256,3), dtype=np.float32)\n",
    "    else:\n",
    "        X_batch = np.zeros((batch_size,256,256,3), dtype=np.float32)\n",
    "        \n",
    "    k = 0\n",
    "    for index in range(index1, index2, 1):\n",
    "        d = pydicom.read_file(parsed[all_img_ids[index]]['dicom'])\n",
    "        im = d.pixel_array\n",
    "        im = np.stack([im] * 3, axis=2)\n",
    "        im = cv2.resize(im, (256,256), interpolation = cv2.INTER_AREA)\n",
    "        X_batch[k] = im\n",
    "        k = k + 1\n",
    "        \n",
    "        if aug:\n",
    "            rot_mat = cv2.getRotationMatrix2D((128,128), 30, 1.0)\n",
    "            rot30 = cv2.warpAffine(im, rot_mat, (256,256))\n",
    "            X_batch[k] = rot30\n",
    "            k = k + 1\n",
    "\n",
    "            rot_mat = cv2.getRotationMatrix2D((128,128), -30, 1.0)\n",
    "            rot30 = cv2.warpAffine(im, rot_mat, (256,256))\n",
    "            X_batch[k] = rot30        \n",
    "            k = k + 1\n",
    "\n",
    "            blurred = cv2.GaussianBlur(im,(5,5),cv2.BORDER_DEFAULT)\n",
    "            X_batch[k] = blurred        \n",
    "            k = k + 1\n",
    "    \n",
    "    return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marked_imgs(index1, index2, aug):\n",
    "    size = 128\n",
    "    \n",
    "    if aug:\n",
    "        Y_batch = np.zeros((batch_size*4,size,size,3), dtype=np.float32)\n",
    "    else:\n",
    "        Y_batch = np.zeros((batch_size,size,size,3), dtype=np.float32)\n",
    "        \n",
    "    k = 0\n",
    "    for index in range(index1, index2, 1):\n",
    "        img_black = np.zeros((size,size,3), np.float32)\n",
    "        \n",
    "        x = str(df_class.loc[df_class['patientId'] == all_img_ids[index]]['class'])\n",
    "        \n",
    "        if(x.split(' ')[4] == 'No'):\n",
    "            cv2.rectangle(img_black, (25,25), (50,85), (0,40,0),-1)\n",
    "            cv2.rectangle(img_black, (75,25), (100,85), (0,40,0),-1)\n",
    "        \n",
    "        \n",
    "        for box in parsed[all_img_ids[index]]['boxes']:\n",
    "            y = box[0]\n",
    "            x = box[1]\n",
    "            height = box[2]\n",
    "            width = box[3]\n",
    "            x1 = x*size/1024.0\n",
    "            y1 = y*size/1024.0\n",
    "            x2 = (x + width)*size/1024.0\n",
    "            y2 = (y + height)*size/1024.0\n",
    "            cv2.rectangle(img_black, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0),-1)   \n",
    "            \n",
    "            \n",
    "        Y_batch[k] = img_black #normal img\n",
    "        k = k + 1\n",
    "\n",
    "        if aug:\n",
    "            rot_mat = cv2.getRotationMatrix2D((64,64), 30, 1.0)\n",
    "            rot30 = cv2.warpAffine(img_black, rot_mat, (128,128))\n",
    "            Y_batch[k] = rot30\n",
    "            k = k + 1\n",
    "\n",
    "            rot_mat = cv2.getRotationMatrix2D((64,64), -30, 1.0)\n",
    "            rot30 = cv2.warpAffine(img_black, rot_mat, (128,128))\n",
    "            Y_batch[k] = rot30\n",
    "            k = k + 1\n",
    "\n",
    "            Y_batch[k] = img_black #blurred image\n",
    "            k = k + 1\n",
    "    \n",
    "    return Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(),tf.Session() as sess:\n",
    "    \n",
    "    #for lungs_4_2 batch_size remains same. for lungs_3_5 -> batch_size*4 due to augmentations.\n",
    "    lung_x_input = tf.placeholder(tf.float32,shape=(batch_size*4,256,256,3),name='lung_x_ip')\n",
    "    lung_y_input = tf.placeholder(tf.float32,shape=(batch_size*4,128,128,3),name='lung_y_ip')\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    lung_x_input = lung_x_input/255.0\n",
    "    \n",
    "    hg_output = hourglass_model(lung_x_input, 4, 256, 3, True) # true while training, false during inference\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    #calculate mse losses \n",
    "    lung_y_input = lung_y_input/255.0\n",
    "    total_loss = tf.losses.mean_squared_error(lung_y_input, hg_output)\n",
    "    \n",
    "    ###################################################################################################################\n",
    "    #20180905 rate = 2.5e-4. 740 - 648-444-300\n",
    "    #2018105 same rate loss 300-288\n",
    "    #lungs_4_2 loss upto 270, lungs_3_5 loss up to 250\n",
    "    #lungs_4_2 with green masks and red masks no aug\n",
    "    #lungs_3_5 green and red masks with aug\n",
    "    learning_rate = 2.5e-4\n",
    "    run = 6\n",
    "    training_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "    num_epochs = 3\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ###################################################################################################################\n",
    "    \n",
    "    restore_model = True\n",
    "    save_model = True\n",
    "    train_data = True\n",
    "    \n",
    "    #restore variable values. while saving the model further below, im only saving variable values and not the graph. \n",
    "    if(restore_model):\n",
    "        saver =  tf.train.Saver()  \n",
    "        saver.restore(sess,'../models/20181015/lungs_3_5')\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    if train_data:   \n",
    "        \n",
    "        num_minibatch = int(number_train_images/batch_size)\n",
    "        \n",
    "        for i in range(num_epochs+1):\n",
    "            print(\"epoch number is \", i)\n",
    "            batch_loss = 0.0\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            for j in range(num_minibatch):\n",
    "                #all img ids have all ids of img in shuffled way\n",
    "                temp_x_content = get_lung_imgs(j*batch_size,batch_size*(j+1), True)\n",
    "                temp_y_content = get_marked_imgs(j*batch_size,batch_size*(j+1), True)\n",
    "\n",
    "                _,tl = sess.run([training_step,total_loss], feed_dict={lung_x_input:temp_x_content, \n",
    "                                                                       lung_y_input:temp_y_content})\n",
    "                batch_loss += tl/num_minibatch\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(\"total loss is \", batch_loss)\n",
    "            print(\"epoch time is \", (end_time - start_time))\n",
    "\n",
    "            #save the model without the graph.\n",
    "            if(save_model and i%1 == 0):\n",
    "                saver_2 = tf.train.Saver()  \n",
    "                saver_2.save(sess,\"../models/20181015/lungs_\" + str(i) + \"_\" + str(run),write_meta_graph=False) \n",
    "    ###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
